## 数据采集与消费

flume：适合下游数据消费者不多的情况；适合数据安全性要求不高的操作；

kafka：适合数据下游消费众多的情况；适合数据安全性要求较高的操作（支持replication）；

在实时计算中，通常是数据通过flume采集到kafka然后供给给hbase消费

**因此常用的一种模型是：**线上数据 --> flume --> kafka --> flume(根据情景增删该流程) --> HDFS

本项目中，使用flume监控/opt/module/data/call.log文件中内容变化，将变化的数据采集放入kafka中，等待消费。

### 数据采集

数据通过flume进行采集，采集后等待ct-consumer消费数据，ct-cosumer消费数据是将数据存储在hbase中。

kafka集群是依赖于zookeeper集群的，所以使用kafka集群之前，首先需要安装配置zookeeper集群

```shell
# 启动zookeeper和kafka集群
zk.sh start
kafka start

# 创建kafka主题
bin/kafka-topics.sh --zookeeper hadoop102:2181 --topic ct --create --replication-factor 2 --partitions 3

# 查看主题是否创建成功
bin/kafka-topics.sh --zookeeper hadoop102:2181 --list ct

# 启动kafka控制台消费者，等待flume的信息输入
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic ct --from-beginning

# 配置flume，flume-2-kafka.conf,文件内容如下
# define
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F -c +0 /opt/module/data/call.log
a1.sources.r1.shell = /bin/bash -c

# sink
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sinks.k1.kafka.topic = calllog
a1.sinks.k1.kafka.flumeBatchSize = 20
a1.sinks.k1.kafka.producer.acks = 1
a1.sinks.k1.kafka.producer.linger.ms = 1

# channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# bind
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

# 启动flume
bin/flume-ng agent -c conf/ -n a1 -f /opt/module/data/flume-2-kafka.conf
```

### 数据消费

数据消费的是通过flume采集放入kafka中的数据，用于消费数据，将产生的数据实时存储在HBase中。

这里需要注意，maven的pom.xml文件中需要引入kafka和hbase的jar，项目需要从kafka中取数据，并放入hbase中，但是这里有一个坑，就是一个项目中，子模块之间的相互引用，重复的jar包是可以不用写的，如果重复写，可能会报错

