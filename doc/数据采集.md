## 数据采集与消费

flume：适合下游数据消费者不多的情况；适合数据安全性要求不高的操作；

kafka：适合数据下游消费众多的情况；适合数据安全性要求较高的操作（支持replication）；

在实时计算中，通常是数据通过flume采集到kafka然后供给给hbase消费

**因此常用的一种模型是：**线上数据 --> flume --> kafka --> flume(根据情景增删该流程) --> HDFS

本项目中，使用flume监控/opt/module/data/call.log文件中内容变化，将变化的数据采集放入kafka中，等待消费。

### 数据采集

数据通过flume进行采集，采集后等待ct-consumer消费数据，ct-cosumer消费数据是将数据存储在hbase中。

kafka集群是依赖于zookeeper集群的，所以使用kafka集群之前，首先需要安装配置zookeeper集群

```shell
# 启动zookeeper和kafka集群
zk.sh start
kafka start

# 创建kafka主题
bin/kafka-topics.sh --zookeeper hadoop102:2181 --topic ct --create --replication-factor 2 --partitions 3

# 查看主题是否创建成功
bin/kafka-topics.sh --zookeeper hadoop102:2181 --list ct

# 启动kafka控制台消费者，等待flume的信息输入
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic ct --from-beginning

# 配置flume，flume-2-kafka.conf,文件内容如下
# define
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F -c +0 /opt/module/data/call.log
a1.sources.r1.shell = /bin/bash -c

# sink
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sinks.k1.kafka.topic = calllog
a1.sinks.k1.kafka.flumeBatchSize = 20
a1.sinks.k1.kafka.producer.acks = 1
a1.sinks.k1.kafka.producer.linger.ms = 1

# channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# bind
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

# 启动flume
bin/flume-ng agent -c conf/ -n a1 -f /opt/module/data/flume-2-kafka.conf
```

### 数据消费

数据消费的是通过flume采集放入kafka中的数据，用于消费数据，将产生的数据实时存储在HBase中。

这里需要注意，maven的pom.xml文件中需要引入kafka和hbase的jar，项目需要从kafka中取数据，并放入hbase中，但是这里有一个坑，就是一个项目中，子模块之间的相互引用，重复的jar包是可以不用写的，如果重复写，可能会报错

数据的消费，和数据模拟生产类似，也要面向接口编程

经过分析，可以将程序分为如下接口和实现类：

1. Consumer接口，继承Closeable类，该接口有一个consume方法
2. CallLogConsumer类，实现了Consumer接口，实现了Consumer接口中的consume方法，从kafka中取数据，并存入Hbase
3. BaseDao类，用于编写通用的操作hbase类
4. HbaseDao类，继承于BaseDao类，用于编写出入数据等方法
5. Calllog类，这里应用注解的方法，首先定了三个注解类，分别为表名，rowkey，和列名，用于动态的获取数据
6. 注解，Column:定义了family和column，并指定默认值，Rowkey，和TableRef：定义了表名称

注意点：

1. 获取项目中resources文件夹下的文件的方法

   ```java
   Properties prop = new Properties();         prop.load(Thread.currentThread().getContextClassLoader().getResourceAsStream("consumer.properties"));
   ```

2. java连接kafka，需要配置信息，然后需要kafka和kafka-client的jar包

   ```java
   Properties prop = new Properties();     prop.load(Thread.currentThread().getContextClassLoader().getResourceAsStream("consumer.properties"));
   //获取Flume采集的数据
   KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(prop);
   // 关注主题
   consumer.subscribe(Arrays.asList(Names.TOPIC.getValue()));
   //消费数据
   while (true) {
       ConsumerRecords<String, String> consumerRecords = consumer.poll(100);
       for (ConsumerRecord<String, String> consumerRecord : consumerRecords) {
           System.out.println(consumerRecord.value());
           dao.insertData(consumerRecord.value());
       }
   }
   
   // 配置信息
   bootstrap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092
   key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
   value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
   group.id=lelandyan
   enable.auto.commit=true
   auto.commit.interval.ms=1000
   ```

3. 协处理器需要继承RegionObserver, RegionCoprocessor,并重写Optional,和postPut,注意协处理器需要进入hbase两个jar包，然后打包将其上传到hbase下的lib中，成为依赖

   ```java
   tableDescriptor.addCoprocessor(coprocessorClass);
   ```

   ```java
   package com.lelandyan.ct.consumer.coprocessor;
   
   import com.lelandyan.ct.common.bean.BaseDao;
   import com.lelandyan.ct.common.constant.Names;
   import org.apache.hadoop.hbase.TableName;
   import org.apache.hadoop.hbase.client.Durability;
   import org.apache.hadoop.hbase.client.Put;
   import org.apache.hadoop.hbase.client.Table;
   import org.apache.hadoop.hbase.coprocessor.ObserverContext;
   import org.apache.hadoop.hbase.coprocessor.RegionCoprocessor;
   import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;
   import org.apache.hadoop.hbase.coprocessor.RegionObserver;
   import org.apache.hadoop.hbase.util.Bytes;
   import org.apache.hadoop.hbase.wal.WALEdit;
   
   import java.io.IOException;
   import java.util.Optional;
   
   
   public class InsertCalleeCoprocessor implements RegionObserver, RegionCoprocessor {
       @Override
       public Optional<RegionObserver> getRegionObserver() {
           return Optional.of(this);
       }
   
       @Override
       public void postPut(ObserverContext<RegionCoprocessorEnvironment> c, Put put, WALEdit edit, Durability durability) throws IOException {
           //Table table = c.getEnvironment().getTable(TableName.valueOf(Names.TABLE.getValue()));
           //Table table = c.getEnvironment().createConnection(c.getEnvironment().getConfiguration()).getTable(TableName.valueOf(Names.TABLE.getValue()));
   //        Table table = c.getEnvironment().getConnection().getTable(TableName.valueOf(Names.TABLE.getValue()));
           TableName tn = TableName.valueOf(Names.TABLE.getValue());
           Table table = c.getEnvironment().createConnection(c.getEnvironment().getConfiguration()).getTable(tn);
   
   
           String rowKey = Bytes.toString(put.getRow());
           String[] values = rowKey.split("_");
   
           CoprocessorDao dao = new CoprocessorDao();
           String call1 = values[1];
           String call2 = values[3];
           String callTime = values[2];
           String duration = values[4];
           String flg = values[5];
   
   //        System.out.println("corprocessor go.........................");
           System.out.println(flg);
           if ("1".equals(flg)) {
   //            System.out.println("corprocessor begin......................");
               String calleerowKey = dao.getRegionNum(call2, callTime) + "_" + call2 + "_" + callTime + "_" + call1 + "_" + duration + "_0";
   
               Put calleeput = new Put(Bytes.toBytes(calleerowKey));
               byte[] calleefamily = Bytes.toBytes(Names.CF_CALLEE.getValue());
               calleeput.addColumn(calleefamily, Bytes.toBytes("call1"), Bytes.toBytes(call2));
               calleeput.addColumn(calleefamily, Bytes.toBytes("call2"), Bytes.toBytes(call1));
               calleeput.addColumn(calleefamily, Bytes.toBytes("callTime"), Bytes.toBytes(callTime));
               calleeput.addColumn(calleefamily, Bytes.toBytes("duration"), Bytes.toBytes(duration));
               calleeput.addColumn(calleefamily, Bytes.toBytes("flg"), Bytes.toBytes("0"));
               table.put(calleeput);
   
   //            System.out.println("corprocessor end......................");
   
           }
           table.close();
   
       }
   
       private class CoprocessorDao extends BaseDao {
           public int getRegionNum(String tel, String time) {
               return genRegionNum(tel, time);
           }
       }
   }
   ```

4. 注解方法，这里可以懂编写注解类的方法，动态的获取数据，讲要设置的数据变成一个类的字段，在运行的时候获取字段数据，增强程序的可扩展性，首先需要编写注解类，然后使用注解修饰要获取数据的字段，然后动态获取

   ```java
   protected void putData(Object obj) throws Exception {
       Class clazz = obj.getClass();
       TableRef tableRef = (TableRef)clazz.getAnnotation(TableRef.class);
       String tableName = tableRef.value();
       String stringrowKey = "";
       Field[] fs = clazz.getDeclaredFields();
       for (Field f : fs) {
           Rowkey rowkey = f.getAnnotation(Rowkey.class);
           if(rowkey!=null){
               f.setAccessible(true);
               stringrowKey = (String) f.get(obj);
               break;
           }
       }
   
       Connection conn = getConnection();
       Table table = conn.getTable(TableName.valueOf(tableName));
       Put put = new Put(Bytes.toBytes(stringrowKey));
   
       for (Field f : fs) {
           Column column = f.getAnnotation(Column.class);
           if(column!=null){
               f.setAccessible(true);
               String family = column.family();
               String colName = column.column();
               if(colName == null || "".equals(colName)){
                   colName = f.getName();
               }
               f.setAccessible(true);
               String value = (String) f.get(obj);
   
               put.addColumn(Bytes.toBytes(family),Bytes.toBytes(colName),Bytes.toBytes(value));
           }
       }
   
       table.put(put);
   
       table.close();
   }
   ```

   ```java
   package com.lelandyan.ct.common.api;
   
   import java.lang.annotation.Retention;
   import java.lang.annotation.RetentionPolicy;
   import java.lang.annotation.Target;
   
   import static java.lang.annotation.ElementType.FIELD;
   
   @Target({FIELD})
   @Retention(RetentionPolicy.RUNTIME)
   public @interface Column {
       String family() default "info";
       String column() default  "";
   }
   ```

   ```java
   package com.lelandyan.consumer.bean;
   
   import com.lelandyan.ct.common.api.Column;
   import com.lelandyan.ct.common.api.Rowkey;
   import com.lelandyan.ct.common.api.TableRef;
   
   @TableRef("ct:calllog")
   
   public class Calllog {
       @Rowkey
       private String rowKey;
       @Column(family = "caller")
       private String call1;
       @Column(family = "caller")
       private String call2;
       @Column(family = "caller")
       private String callTime;
       @Column(family = "caller")
       private String duration;
       @Column(family = "caller")
       private String flg = "1";
       private String name;
   
       public String getFlg() {
           return flg;
       }
   
       public void setFlg(String flg) {
           this.flg = flg;
       }
   
   
   
       public Calllog(){
   
       }
   
       public String getRowKey() {
           return rowKey;
       }
   
       public void setRowKey(String rowKey) {
           this.rowKey = rowKey;
       }
   
       public Calllog(String data){
           String[] values = data.split("\t");
           call1 = values[0];
           call2 = values[1];
           callTime = values[2];
           duration = values[3];
       }
   
   
       public String getCall1() {
           return call1;
       }
   
       public void setCall1(String call1) {
           this.call1 = call1;
       }
   
       public String getCall2() {
           return call2;
       }
   
       public void setCall2(String call2) {
           this.call2 = call2;
       }
   
       public String getCallTime() {
           return callTime;
       }
   
       public void setCallTime(String callTime) {
           this.callTime = callTime;
       }
   
       public String getDuration() {
           return duration;
       }
   
       public void setDuration(String duration) {
           this.duration = duration;
       }
   }
   ```

   

